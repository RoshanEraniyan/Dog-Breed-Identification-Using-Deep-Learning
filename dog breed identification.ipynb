{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0956a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "447fbe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"labels.csv\")\n",
    "train_file = 'train/'\n",
    "test_file = 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92f1abc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique Dog Breeds : 120\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of unique Dog Breeds :\",len(labels.breed.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bb3f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_breeds = 60\n",
    "im_size = 224\n",
    "batch_size = 64\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4eacd555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new list for 60 breeds\n",
    "breed_dict = list(labels['breed'].value_counts().keys()) \n",
    "new_list = sorted(breed_dict,reverse=True)[:num_breeds*2+1:2]\n",
    "labels = labels.query('breed in @new_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccd5cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['img_file'] = labels['id'].apply(lambda x: x + \".jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "972e7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding and Scaleing imagess\n",
    "train_x = np.zeros((len(labels), im_size, im_size, 3), dtype='float32')\n",
    " \n",
    "\n",
    "for i, img_id in enumerate(labels['img_file']):\n",
    "  \n",
    "  img = cv2.resize(cv2.imread(train_file+img_id,cv2.IMREAD_COLOR),((im_size,im_size)))\n",
    " \n",
    "  img_array = preprocess_input(np.expand_dims(np.array(img[...,::-1].astype(np.float32)).copy(), axis=0))\n",
    "  #update the train_x variable with new element\n",
    "  train_x[i] = img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c23985e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = encoder.fit_transform(labels[\"breed\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c7fe5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_x,train_y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab59c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.25,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3abd8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50V2(input_shape = [im_size,im_size,3], weights='imagenet', include_top=False)\n",
    "#freeze all trainable layers and train only top layers \n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = resnet.output\n",
    "x = BatchNormalization()(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "#add fully connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "162da89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(num_breeds, activation='relu')(x)\n",
    " \n",
    "#create model class with inputs and outputs\n",
    "model = Model(inputs=resnet.input, outputs=predictions)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fdfa42b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "64/64 [==============================] - 461s 7s/step - loss: 4.4284 - accuracy: 0.0231 - val_loss: 4.1143 - val_accuracy: 0.0283\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 349s 5s/step - loss: 4.1585 - accuracy: 0.0233 - val_loss: 4.1128 - val_accuracy: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    " \n",
    "#using RMSprop optimizer to compile or build the model\n",
    "optimizer = RMSprop(learning_rate=learning_rate,rho=0.9)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])\n",
    " \n",
    "#fit the training generator data and train the model\n",
    "hist = model.fit(train_generator,\n",
    "                 steps_per_epoch= x_train.shape[0] // batch_size,\n",
    "                 epochs= epochs,\n",
    "                 validation_data= test_generator,\n",
    "                 validation_steps= x_test.shape[0] // batch_size)\n",
    " \n",
    "#Save the model for prediction\n",
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85a6aa70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted Breed for this Dog is : afghan_hound\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model = load_model(\"model\")\n",
    " \n",
    "#get the image of the dog for prediction\n",
    "pred_img_path = 'afghan_hound.jpeg'\n",
    "\n",
    "# check that the file exists\n",
    "if not os.path.exists(pred_img_path):\n",
    "    print(f\"Error: File '{pred_img_path}' not found\")\n",
    "    exit(1)\n",
    "\n",
    "#read the image file and convert into numeric format\n",
    "#resize all images to one dimension i.e. 224x224\n",
    "pred_img = cv2.imread(pred_img_path,cv2.IMREAD_COLOR)\n",
    "\n",
    "# check that the image was read successfully\n",
    "if pred_img is None:\n",
    "    print(f\"Error: Failed to read image '{pred_img_path}'\")\n",
    "    exit(1)\n",
    "\n",
    "# check that the image has a valid size\n",
    "if pred_img.shape[0] < im_size or pred_img.shape[1] < im_size:\n",
    "    print(f\"Error: Image '{pred_img_path}' is too small\")\n",
    "    exit(1)\n",
    "\n",
    "pred_img_array = cv2.resize(pred_img,((im_size,im_size)))\n",
    "\n",
    "#scale array into the range of -1 to 1.\n",
    "#expand the dimension on the axis 0 and normalize the array values\n",
    "pred_img_array = preprocess_input(np.expand_dims(np.array(pred_img_array[...,::-1].astype(np.float32)).copy(), axis=0))\n",
    " \n",
    "#feed the model with the image array for prediction\n",
    "pred_val = model.predict(np.array(pred_img_array,dtype=\"float32\"))\n",
    " \n",
    "#display the image of dog\n",
    "cv2.imshow(\"TechVidvan\", cv2.resize(pred_img,(im_size,im_size))) \n",
    " \n",
    "#display the predicted breed of dog\n",
    "pred_breed = sorted(new_list)[np.argmax(pred_val)]\n",
    "print(\"Predicted Breed for this Dog is :\",pred_breed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
